% Chapter 1
\externaldocument{chapter3}
\externaldocument{chapter4}
\chapter{Introduction} % Main chapter title

\label{Chapter1} % For referencing the chapter elsewhere, use \ref{Chapter1} 

%----------------------------------------------------------------------------------------

% Define some commands to keep the formatting separated from the content 
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------

%\section{Welcome and Thank You}

Computers have been used to automate discovery and management of music in so many different ways. Automating the task of attaching a semantic meaning to a song is popularly known as \textit{music auto-tagging}. Automatic tagging algorithms have been used to build recommendation systems that allow listeners to discover songs that match their taste. It also enables online music stores to filter their target audience. But semantic description of a song is not straightforward and there is this gap between music audio and listener's description, both linguistically and emotionally, which we term as \textit{audio-semantic gap}. In this thesis, we test the state-of-art approaches of music auto-tagging on a dataset that is least affected by \textit{audio-semantic} noise. In section \ref{motivation}, the need for this dedicated research is explained by describing some shortcomings of the currently available solution approaches. In section \ref{overview}, a top to bottom overview of the contents of this research is presented.   

%----------------------------------------------------------------------------------------

\section{Motivation}
\label{motivation}
Captioning music from the point of view of an artist is an interesting application. Training an algorithm to do so takes music auto-tagging a step towards human intelligence. Although great technical progress have been made to enable efficient retrieval and organization of audio content, analysing music and communicating it's artistic properties is still challenging. Current music recommendation systems fall short in providing recommendations based of aesthetics of music because of the reasons described below,
  
\subsection{Cold start problem with collaborative filtering methods}
When the usage data is available, one can use collaborative filtering to recommend the tracks on a community-based trending lists (say, a community of experts). That is, if a listener liked songs A and B and you liked A, you might also like B. Such algorithms have proven to be extremely efficient and out-perform those algorithms that works by extracting acoustic cues from audio signal for the task of finding similar songs \cite{DC1}. However, in absence of such usage data, one resorts to content-based methods, where just the audio signal is used for generating recommendations. Thus collaborative filtering methods suffer from what is called a \textit{cold start problem}, making it less efficient for new and unpopular songs. 


\subsection{Problems with content based methods}
\label{problems}
Using information from audio content to overcome the cold-start problem resulted in \textit{content-based} recommendation methods. In such algorithms, a classifier is trained on some training data to learn acoustic cues. But a recommendation system can also be built without requiring  such acoustic labels by combining \textit{content based} and \textit{collaborative} techniques[combining content] and training it from a collaborative view point. However, this is not sufficient if a recommendation system has to designed for artists and composers who search for songs based on some properties of music itself. In such cases, the current \textit{content-based} methods fall short because of following training assumption,   

\subsubsection{Psychoacoustic assumptions}
Music descriptions are often affected by social factors. However, it is possible to measure what percentage of subjects classify a music to certain mood (say, happy, dull etc.) and present the popular description. The currently available large datasets are built on this assumption \cite{MSD}\cite{MTT}. Algorithms trained on such datasets may converge to learning social descriptions rather than actual descriptions termed by experts for the properties of music (also termed as \textit{aesthetics} in popular journals of music psychology [no account for taste..]). This psychoacoustic assumption stands as a barrier to discover songs based on aesthetics (which has applications in music therapy \cite{MusicTherapy}).

\subsubsection{Temporal summarization of audio content}
The current state of art music tagging algorithms\cite{choi_crnn}\cite{MultiScale} are established by training on datasets that contain just short music excerpts. In run-time, these algorithms classify each short section separately and merge tags across different sections. It is not clear if such section-wise mearging can approximate actual properties of the whole song. Hence there is a need to test algorithms that extract features approximating greater length of the song. 

\subsection{Need for adaptive glossary}
Current recommendation systems including the ones that use collaborative filtering, restrict the user with the choice of tags. Moreover, it is not guaranteed that all users will perceive all the tags in the same way. A recent study in idiographic music psychology have indicated that different people use different aesthetic criteria to make judgement about music\cite{NoAccountingForTaste}. Hence it would be interesting to study if these models \cite{choi_cnn}\cite{choi_crnn} trained on large datasets can be exploited for training on personal repertoire, which are usually small.  

%----------------------------------------------------------------------------------------

\section{Overview}
\label{overview}
Convolution neural networks (CNN) have recently gained popularity for content-based multi-label classification task achieving state-of-art performance on established datasets\cite{choi_cnn}\cite{choi_rnn}. But these models were trained on large amount of training data containing short excerpts of music. But an artist might describe the music as a whole and not in sections. At the same time, gathering such data is also expensive. So the aim of this thesis is to find out
\begin{itemize}
\setlength\itemsep{0em}
\item If the CNN models trained on large data can be exploited to extract features from smaller dataset.
\item An estimation of performance for features that approximate longer audio.
\end{itemize} 
    
In the following work, content-based multi-label classification algorithms are tested on a repository of clean tags, free from social bias. The machine learning assumption is that if we show an algorithm enough examples, the correlation between human tags and predicted tags will become clear. The classification is done on a lower dimensional approximation of the audio signal known as \textit{feature}. The general pipeline for music feature extraction is \textit{signal representation}, systematic \textit{dimensionality-reduction} followed by \textit{temporal approximation}.
  



\subsection{Supervised training on repository with aesthetic tags }
 Thus, a properly labelled training set is usually required to solve the task of automatic tagging. 

In this thesis, a repository labelled with aesthetic judgements of songs is used. An aesthetic judgement is a subjective evaluation of a piece of music as art based on an individual set of aesthetic properties. [from everyday .. ] An aesthetic judgement is assumed to rely more on ‘higher’ cognitive functions , domain relevant knowledge, and a fluid, individualized process that may change across time and context. We discuss how aesthetic judgements influence preference for a song. In a recent work in experimental music psychology, strong correlation have been found between the two. But it is also shown that such preferences also vary widely between cultural contexts. ( see ) This also justifies the need for adaptive glossaries in recommendation systems. 

\subsection{Convolutional neural network for feature extraction}
The input signal preprocessed to spectrogram is mapped to the feature space by convolving hierarchically with learnable filters. (see ch.2,1) Conceptual arguments have been made to demonstrate that deep processing models are powerful extensions of hand-crafted feature extraction methods\cite{Yann}. (see ch.3.1) It is also shown that deep layers learn to capture textures and patterns of continuous distribution on a spectrogram for music classification task. [explaining cNN for music class]. (see ch 3.2).  we discuss the ability of these CNN models to be fine tuned on a medium sized dataset (see ch ). Convolutions over log amplitude mel spectrogram and MFCC are studied (see ch)



\subsection{ Recurrent neural network for temporal summarization of features}
 The features extracted on every 29.1s time frame are then sent to sequence to one RNN. This leaves us with a feature of fixed dimension for audio of arbitrary length up to five minutes. (see ch ). Here we make an assumption that a listener can make an aesthetic judgement within 5 minutes. Conceptual comparisons of RNN with the state of art temporal feature pooling technique in [ ] have been discussed (see ) . Effectiveness of temporal summarization have been justified by comparing with the performance of section-wise merging of tags ( see )

\subsection{ classification }
The features are then mapped to the probability space of labels. Multilayer perceptron with binary cross entropy loss is used for training. End to end training is compared with two-stage method, separating  training of features and training of classifier ( see ch ). In the two-stage approach, MLP is compared with SVM classifier. ( see )



%----------------------------------------------------------------------------------------

\section{Outline of the report}
In chapter 2, the terminologies and mathematical formulations are elaborated. Advanced readers can skip this chapter. In chapter 3, a detailed overview of previous research, their shortcomings for the current problem along with justification for proposed models are discussed. In Chapter 4, details of the dataset, implementations and the experiment results of proposed models are discussed. In chapter 5, the results are analysed and the need for biologically motivated feature extraction techniques are discussed. 






