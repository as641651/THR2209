\documentclass{book}

\addtolength{\textwidth}{3cm}  \addtolength{\oddsidemargin}{-1.5cm}  \addtolength{\evensidemargin}{-1.5cm}
\addtolength{\textheight}{1cm} \addtolength{\topmargin}{-.3cm}

\usepackage{amssymb}
\usepackage{amsmath,bm}

\usepackage{booktabs}
\usepackage{aicescover}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=blue,  %choose some color if you want links to stand out
}

\usepackage[
backend=bibtex8,
sorting=ynt,
maxbibnames=99
]{biblatex}
\addbibresource{bibliography.bib}

\linespread{1.1}
\pagestyle{plain}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{placeins}
%\usepackage{algorithm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{glossaries}
\usepackage{appendix}
\usepackage{xr}
\usepackage{color}


\makeglossaries
\loadglsentries{glossary.tex}

\graphicspath{ {Figures/} }

\begin{document}

\aicescovertitle{Analyses of Convolutional Neural Networks for Automatic tagging of music tracks }
\aicescoverauthor{{\bf Master Thesis}\\Aravind Sankaran}
\aicescoversupervisor{Prof. Paolo Bientinesi \\ Prof. Marco Alunno}
\aicescoverexaminer{Prof. Paolo Bientinesi \\ Prof. Bastian Leibe}
\aicescoverpage


\section*{Abstract}

Describing music can be quite tricky and talking about music may simply require as much vocabulary as any technical subject. Musicians and composers usually discuss their work with jargon describing certain aesthetics of the song. As the amount of music recordings are constantly growing, finding a song that matches these aesthetic description is challenging. This work is an attempt to take a step towards developing algorithms that could tag music like an artist. The currently available state-of-art algorithms are trained and tested on datasets with tags that are socially biased. In this thesis, a classifier is trained on a repertoire of 900 songs with carefully labelled data. The Mel-Frequency-Cepstral-Coefficients (MFCC) features are compared with features extracted by pre-trained Convolution Neural Networks (CNN) over mel-log power spectrogram. These features are extracted every 29.1s and approximated over time to a fixed size representation. The temporal approximation by sequence to one Long Term Short Memory (LSTM) Recurrent Neural Network is compared with approximation by Bag of Frames (BoF) approach and the weighted area under receiver operating characteristic curve (AUC) is reported. The experiments show that MFCC features summarized by LSTM outperforms pre-trained convolutions counterpart. It is also seen that LSTM perform better than Bag of Frames features for temporal approximation.     

\vspace{5cm}


\newpage

\section*{\bf Acknowledgments}
[TODO]
\tableofcontents

\include{Chapters/Chapter1}
\include{Chapters/Chapter2}
\include{Chapters/Chapter3}
\include{Chapters/Chapter4}
\include{Appendices/AppendixA}
%\chapter{Introduction}
%
%\section{Related work}
%
%Use of references: \cite{BTO,Eigen3}
%
%\section{Outline of the thesis}
%
%\chapter{Chapter title}
%
%\chapter{Experimental results}
%
%\chapter{Conclusions and future work}


%\printbibliography[
%heading=bibintoc,
%title={Bibliography}
%]
 
\printglossaries
\chapter*{Bibliography}
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography[type={inproceedings},title={Proceedings},heading=subbibliography]
\printbibliography[type={article},title={Articles},heading=subbibliography]
\printbibliography[keyword={preprint},title={Pre-Prints},heading=subbibliography]
\printbibliography[type={book},title={Books},heading=subbibliography]
\printbibliography[type={misc},title={Misc},heading=subbibliography]

\end{document}
