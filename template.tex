\documentclass{book}

\addtolength{\textwidth}{3cm}  \addtolength{\oddsidemargin}{-1.5cm}  \addtolength{\evensidemargin}{-1.5cm}
\addtolength{\textheight}{1cm} \addtolength{\topmargin}{-.3cm}

\usepackage{amssymb}
\usepackage{amsmath,bm}

\usepackage{booktabs}
\usepackage{aicescover}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true, %set true if you want colored links
    linktoc=all,     %set to all if you want both sections and subsections linked
    linkcolor=blue,  %choose some color if you want links to stand out
}

\usepackage[
backend=bibtex8,
sorting=ynt,
maxbibnames=99
]{biblatex}
\addbibresource{bibliography.bib}

\linespread{1.1}
\pagestyle{plain}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{placeins}
%\usepackage{algorithm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{glossaries}
\usepackage{appendix}
\usepackage{xr}


\makeglossaries
\loadglsentries{glossary.tex}

\graphicspath{ {Figures/} }

\begin{document}

\aicescovertitle{Analyses of Convolutional Neural Networks for Automatic tagging of music tracks }
\aicescoverauthor{{\bf Master Thesis}\\Aravind Sankaran}
\aicescoversupervisor{Prof. Paolo Bientinesi \\ Prof. Marco Alunno}
\aicescoverexaminer{Prof. Paolo Bientinesi \\ Prof. Bastian Leibe}
\aicescoverpage


\section*{Abstract}

Describing music can be quite tricky and talking about music may simply require as much vocabulary as any technical subject. Musicians and composers usually discuss their work with jargon describing certain aesthetics of the song. As the amount of music recordings are constantly growing, finding a song that matches these aesthetic description is challenging. Hence there is a need for algorithms that could tag music like an artist. The currently available state-of-art algorithms are trained and tested on datasets with tags that are socially biased. In this thesis, the classifier is trained on a repertoire with carefully labelled data. The digital signal is transformed to time-frequency representation with frequency in mel-scale and coefficients that are proportional to loudness, resulting in mel-log power spectrogram. The MFCC features are compared with features extracted by fine-tuned Convolution Neural Networks (CNN) on mel-log power spectrogram. These features are extracted every 29.1s and approximated to a fixed size representation. This temporal approximation by sequence to one Long Term Short Memory (LSTM) Recurrent Neural Network is compared with approximation by Bag of Words (BoW) approach and the weighted area under receiver operating characteristic curve (AUC) is reported. The experiments show that MFCC features summarized by LSTM outperforms fine-tuned convolutions counterpart. It is also seen that LSTM perform better than Bag of Words features for temporal approximation.     

\vspace{5cm}


\newpage

\section*{\bf Acknowledgments}

\tableofcontents

\include{Chapters/Chapter1}
\include{Chapters/Chapter2}
\include{Chapters/Chapter3}
\include{Chapters/Chapter4}
\include{Appendices/AppendixA}
%\chapter{Introduction}
%
%\section{Related work}
%
%Use of references: \cite{BTO,Eigen3}
%
%\section{Outline of the thesis}
%
%\chapter{Chapter title}
%
%\chapter{Experimental results}
%
%\chapter{Conclusions and future work}


%\printbibliography[
%heading=bibintoc,
%title={Bibliography}
%]
 
\printglossaries
\chapter*{Bibliography}
\addcontentsline{toc}{chapter}{Bibliography}
\printbibliography[type={inproceedings},title={Proceedings},heading=subbibliography]
\printbibliography[type={article},title={Articles},heading=subbibliography]
\printbibliography[keyword={preprint},title={Pre-Prints},heading=subbibliography]
\printbibliography[type={book},title={Books},heading=subbibliography]
\printbibliography[type={misc},title={Misc},heading=subbibliography]

\end{document}
